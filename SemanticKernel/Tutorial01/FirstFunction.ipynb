{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Your First Function\n",
    "\n",
    "In order to make effective use of Semantic Kernel, let's establish some foundational vocabulary:\n",
    "- **Large Language Model** evolving out of machine learning neural networks, Large Language Models (or LLMs) make use of a pattern known as a *transformer*. The most recent versions of these models have garnered mainstream attention due to the popularity of ChatGPT - a free website that enables anyone to experience artificial intelligence.\n",
    "- **Prompt** the input provided to a Large Language Model (LLM) like those developed by OpenAI. In ChatGPT's web site, the text you enter is the prompt.\n",
    "- **Prompt Template** the text you optionally wrap around the user's input to provide additional instruction and/or context to the LLM.\n",
    "- **Completion** the response from OpenAI. In effect, the OpenAI model is trying to predict - or complete - the words or phrases that are likely to appear after the provided input (prompt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.7.1\"\n",
    "#!import ../config/SettingsHelper.cs\n",
    "using Microsoft.SemanticKernel;\n",
    "\n",
    "MySettings settings = Settings.LoadFromFile();\n",
    "IKernelBuilder builder = Kernel.CreateBuilder();\n",
    "if (settings.Type == \"azure\")\n",
    "    builder.AddAzureOpenAIChatCompletion(\n",
    "        settings.AzureOpenAI.ChatDeployment, \"gpt-35-turbo\", settings.AzureOpenAI.Endpoint, settings.AzureOpenAI.ApiKey);\n",
    "else\n",
    "    builder.AddOpenAIChatCompletion(\n",
    "        settings.OpenAI.Model, settings.OpenAI.ApiKey, settings.OpenAI.OrgId);\n",
    "Kernel kernel = builder.Build();\n",
    "\n",
    "// 1. define your function\n",
    "string promptTemplate = \"\"\"\n",
    "    {{$input}}\n",
    "    Summarize all of the content above.\n",
    "    \"\"\";\n",
    "\n",
    "// 2. attach the function to your kernel\n",
    "KernelFunction summaryFunction = kernel.CreateFunctionFromPrompt(promptTemplate);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above first creates an instance of the Semantic Kernel using the KernelBuilder class. This is the \"brains\" of the Semantic Kernel. The code then adds a reference to your specified completion service (e.g. gpt-35-turbo).\n",
    "\n",
    "1. For your first function, we are just defining a prompt template inline. The functionDefinition is just a string. The {{$input}} is a special type of variable that Semantic Kernel will swap out with the user's input. (We'll talk more about variables in a later tutorial.)\n",
    "2. Now we'll add the prompt template to our kernel instance as a semantic function. You can register multiple functions within a kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// user interaction - feel free to modify this code box and re-run as desired\n",
    "\n",
    "// 3. the prompt is the simple string users will provide to the function\n",
    "string prompt = \"\"\"\n",
    "    If you know the enemy and know yourself, you need not fear the result of a hundred battles. \n",
    "    If you know yourself but not the enemy, for every victory gained you will also suffer a defeat. \n",
    "    If you know neither the enemy nor yourself, you will succumb in every battle.\n",
    "    \"\"\";\n",
    "\n",
    "// 4. invoke the function to pass the prompt as input to the function\n",
    "// NOTE: in Tutorial00, we used the kernel.InvokeAsync() method, but here we use the function.InvokeAsync() method\n",
    "// either option works!\n",
    "FunctionResult result = await summaryFunction.InvokeAsync(kernel, new KernelArguments(){{\"input\", prompt}});\n",
    "\n",
    "// 5. return the result to the user\n",
    "Console.WriteLine(result.GetValue<string>()!);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the code above out into a separate executable segment if you want to provide a different prompt to have OpenAI summarize. \n",
    "\n",
    "3. Here we define the user prompt. As an end user, this may be the text you enter into the user interface. (This is the text you can change if you want to summarize something different).\n",
    "4. When we call the kernel's InvokeAsync method and substitute the input variable with the prompt. InvokeAsync makes the actual call to your OpenAI service and returns with a function result.\n",
    "5. Finally, we write the response from OpenAI to the screen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Enter code in the box below to create your own semantic function to take a favorite quote as input and translate the text to Tolkien dwarvish. (Refer to the code above to get started.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
