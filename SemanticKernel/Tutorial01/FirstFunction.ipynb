{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Your First Function\n",
    "\n",
    "In order to make effective use of Semantic Kernel, let's establish some foundational vocabulary:\n",
    "- **Large Language Model** evolving out of machine learning neural networks, Large Language Models (or LLMs) make use of a pattern known as a *transformer*. The most recent versions of these models have garnered mainstream attention due to the popularity of ChatGPT - a free website that enables anyone to experience artificial intelligence.\n",
    "- **Prompt** the input provided to a Large Language Model (LLM) like those developed by OpenAI. In ChatGPT's web site, the text you enter is the prompt.\n",
    "- **Prompt Template** the text you optionally wrap around the user's input to provide additional instruction and/or context to the LLM.\n",
    "- **Completion** the response from OpenAI. In effect, the OpenAI model is trying to predict - or complete - the words or phrases that are likely to appear after the provided input (prompt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.0.0-rc3</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.0.0-rc3\"\n",
    "#!import ../config/SettingsHelper.cs\n",
    "using Microsoft.SemanticKernel;\n",
    "\n",
    "MySettings settings = Settings.LoadFromFile();\n",
    "KernelBuilder builder = new();\n",
    "if (settings.Type == \"azure\")\n",
    "    builder.AddAzureOpenAIChatCompletion(\n",
    "        settings.AzureOpenAI.ChatDeployment, \"gpt-35-turbo\", settings.AzureOpenAI.Endpoint, settings.AzureOpenAI.ApiKey);\n",
    "else\n",
    "    builder.AddOpenAIChatCompletion(\n",
    "        settings.OpenAI.Model, settings.OpenAI.ApiKey, settings.OpenAI.OrgId);\n",
    "Kernel kernel = builder.Build();\n",
    "\n",
    "// 1. define your function\n",
    "string promptTemplate = \"\"\"\n",
    "    {{$input}}\n",
    "    Summarize all of the content above.\n",
    "    \"\"\";\n",
    "\n",
    "// 2. attach the function to your kernel\n",
    "KernelFunction summaryFunction = kernel.CreateFunctionFromPrompt(promptTemplate);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above first creates an instance of the Semantic Kernel using the KernelBuilder class. This is the \"brains\" of the Semantic Kernel. The code then adds a reference to your specified completion service (e.g. gpt-35-turbo).\n",
    "\n",
    "1. For your first function, we are just defining a prompt template inline. The functionDefinition is just a string. The {{$input}} is a special type of variable that Semantic Kernel will swap out with the user's input. (We'll talk more about variables in a later tutorial.)\n",
    "2. Now we'll add the prompt template to our kernel instance as a semantic function. You can register multiple functions within a kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content above is a quote that emphasizes the importance of knowing both oneself and the enemy in order to succeed in battle. It suggests that if one knows both oneself and the enemy, they need not fear the outcome of a hundred battles. However, if one only knows oneself and not the enemy, they will experience both victory and defeat. And if one knows neither oneself nor the enemy, they will always lose in battle.\r\n"
     ]
    }
   ],
   "source": [
    "// user interaction - feel free to modify this code box and re-run as desired\n",
    "\n",
    "// 3. the prompt is the simple string users will provide to the function\n",
    "string prompt = \"\"\"\n",
    "    If you know the enemy and know yourself, you need not fear the result of a hundred battles. \n",
    "    If you know yourself but not the enemy, for every victory gained you will also suffer a defeat. \n",
    "    If you know neither the enemy nor yourself, you will succumb in every battle.\n",
    "    \"\"\";\n",
    "\n",
    "// 4. invoke the function to pass the prompt as input to the function\n",
    "// NOTE: in Tutorial00, we used the kernel.InvokeAsync() method, but here we use the function.InvokeAsync() method\n",
    "// either option works!\n",
    "FunctionResult result = await summaryFunction.InvokeAsync(kernel, new(prompt));\n",
    "\n",
    "// 5. return the result to the user\n",
    "Console.WriteLine(result.GetValue<string>()!);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the code above out into a separate executable segment if you want to provide a different prompt to have OpenAI summarize. \n",
    "\n",
    "3. Here we define the user prompt. As an end user, this may be the text you enter into the user interface. (This is the text you can change if you want to summarize something different).\n",
    "4. When we call the kernel's InvokeAsync method and substitute the input variable with the prompt. InvokeAsync makes the actual call to your OpenAI service and returns with a function result.\n",
    "5. Finally, we write the response from OpenAI to the screen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Enter code in the box below to create your own semantic function to take a favorite quote as input and translate the text to Tolkien dwarvish. (Refer to the code above to get started.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
