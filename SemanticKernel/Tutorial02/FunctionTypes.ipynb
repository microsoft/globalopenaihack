{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of SK Plugin Functions\n",
    "\n",
    "First, as a reminder, Semantic Kernel allows you to define Plugins (formerly known as Skills) which encapsulate one or more Functions. These functions are where you will engineer your prompts (as well as insert and access variables). There are three types of plugin functions supported:\n",
    "\n",
    "- *Inline*: inline functions are written in your chosen native language. You create the prompt, any variables, and configuration options in your desired language.\n",
    "- *Semantic*: semantic functions are written in something closer to natural language. While this may initially seem too basic or limited, this non-traditional code can often be a very powerful approach in this A.I. world. (\"English is the new programming language.\")\n",
    "- *Native*: like inline functions, native functions are written in your chosen native language, but they allow you to wrap any code logic as a function to be used within the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.7.1\"\n",
    "#!import ../config/SettingsHelper.cs\n",
    "using Microsoft.SemanticKernel;\n",
    "\n",
    "MySettings settings = Settings.LoadFromFile();\n",
    "IKernelBuilder builder = Kernel.CreateBuilder();\n",
    "if (settings.Type == \"azure\")\n",
    "    builder.AddAzureOpenAIChatCompletion(\n",
    "        settings.AzureOpenAI.ChatDeployment, \"gpt-35-turbo\", settings.AzureOpenAI.Endpoint, settings.AzureOpenAI.ApiKey);\n",
    "else\n",
    "    builder.AddOpenAIChatCompletion(\n",
    "        settings.OpenAI.Model, settings.OpenAI.ApiKey, settings.OpenAI.OrgId);\n",
    "Kernel kernel = builder.Build();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Function\n",
    "\n",
    "You can create a function alongside the rest of your code. These inline functions are very easy to implement and may allow for some more complex prompt construstion, but it potentially sacrifices some reusability and maintainability.\n",
    "\n",
    "Run the following code box just once. If you want to run it again, run the code box at the top of this page first otherwise you will keep adding copies of the same function to the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "// 1. define your inline function\n",
    "string functionDefinition = \"\"\"\n",
    "    Write all of the words from the following quote in reverse order. \n",
    "    Treat multiple sentences as a single quote.\n",
    "    Include all words from the quote: {{$input}}\n",
    "    \"\"\";\n",
    "\n",
    "// 2. optionally, you can specify settings for the function\n",
    "OpenAIPromptExecutionSettings executionSettings = new() { \n",
    "    MaxTokens = 100, \n",
    "    Temperature = 0.0\n",
    "};\n",
    "\n",
    "// 3. attach the function to your kernel\n",
    "KernelFunction reverseFunction = kernel.CreateFunctionFromPrompt(functionDefinition, executionSettings);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above shows another example of an inline function - as you've seen in the previous tutorials.\n",
    "\n",
    "1. This is just a simple prompt template string again. And as you've seen previously, we are just using the pre-defined input variable for the Semantic Kernel to swap out.\n",
    "2. The OpenAI API allows for a variety of default settings that you can optionally override as desired to alter the response from the LLM.\n",
    "3. Then we let Semantic Kernel convert that prompt template into a semantic function and register it with our kernel instance for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// 4. the prompt is the simple string users will provide to the function\n",
    "string prompt = \"\"\"\n",
    "    If you know the enemy and know yourself, you need not fear the result of a hundred battles. \n",
    "    If you know yourself but not the enemy, for every victory gained you will also suffer a defeat. \n",
    "    If you know neither the enemy nor yourself, you will succumb in every battle.\n",
    "    \"\"\";\n",
    "\n",
    "// 5. invoke the function to pass the prompt as input to the function - and then the function to OpenAI\n",
    "FunctionResult result = await reverseFunction.InvokeAsync(kernel, new KernelArguments() {{\"input\", prompt}});\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>()!);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. This line represents the user's prompt - the information your end user provides to the LLM. You can modify this to see what other results your users may get when they provide a different prompt to your inline function.\n",
    "5. In this line, we invoke the reverse function (which contains our prompt template) to our kernel instance and provide the user's prompt. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Functions\n",
    "\n",
    "Semantic functions are especially interesting. Up to this point, we defined our functions using traditional C# code and there's a lot of great use cases for doing so. But in a world of A.I., why can't we just use a more natural language to define our function? A semantic function allows for exactly that!\n",
    "\n",
    "Semantic functions are defined by two files - and a particular folder structure. The top-level folder is the plugin (formerly known as a skill) and it contains a variety of related functions. Each function is defined by two files: A config.json file defines the parameters to pass to OpenAI's API and the skprompt.txt file defines the actual prompt and any variables.\n",
    "\n",
    "Before you run the code below, open each of the two files in the Plugins/TranslatePlugin/PigLatinFunction folder.\n",
    "- The most interesting file is the skprompt.txt file which is our function definition. The {{$input}} is a built-in variable that we'll replace with the rest of our prompt. (We'll discuss supporting multiple parameters in our Context Variables tutorial.)\n",
    "- We'll dive into the config.json options in another tutorial, but it's good to at least see what that file contains for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System.IO;\n",
    "\n",
    "// 1. load the plugin from your folder structure\n",
    "string currentDir = Directory.GetCurrentDirectory();\n",
    "string pluginDirectory = Path.Combine(currentDir, \"Plugins\");\n",
    "\n",
    "KernelPlugin translatePlugin = kernel.ImportPluginFromPromptDirectory(\n",
    "    Path.Combine(pluginDirectory, \"TranslatePlugin\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You can store your prompt template and any associated settings as files. This can make your functions both easily used by other Semantic Kernel applications as well as allow business stakeholders to modify the behavior of your function without needing to get into the application code.\n",
    "\n",
    "Semantic Kernel allows you to point it to a local folder in order to add your plugin and functions if you follow it's particular folder structure. In the above example, the first two lines load the Semantic Kernel up with the TranslatePlugin in our Plugins folder. We then pass the prompt into our PigLatinFunction. This function is a child folder of the plugin folder. Within our function folder, there are two files: skprompt.txt and config.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// 2. the prompt is the simple string users will provide to the function\n",
    "string prompt = \"Did you ever dance with the devil in the pale moonlight?\";\n",
    "\n",
    "// 3. run the specified function within a specific plugin\n",
    "FunctionResult result = await kernel.InvokeAsync(translatePlugin[\"ToPigLatin\"], new KernelArguments(){{\"input\", prompt}});\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. This line is just our user prompt again. Put any short sentence in here.\n",
    " 3. The InvokeAsync method again inserts our prompt into the function and sends the entire thing to OpenAI to calculate the completion. (I think the character associated with this quote would appreciate our work here. :D )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native Functions\n",
    "\n",
    "Like inline functions, native functions are written in code. Since it's \"just code\", native functions provide the same opportunity to do anything you can do in code (basically everything! :) )\n",
    "\n",
    "*You'll learn more about native function capabilities in the prompt chaining tutorial.*\n",
    "\n",
    "Before you run the following code, find the OldeEnglishPlugin.cs file in the Plugins folder. Open it up and look at the very simple code to see if you can predict what it's going to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#!import Plugins/OldeEnglishPlugin.cs\n",
    "\n",
    "// 1. load the plugin from a class in your code\n",
    "KernelPlugin oePlugin = kernel.ImportPluginFromObject(new OldeEnglishPlugin());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the code above, we import our plugin from an instance of of our custom class. Native functions allow you to take any custom code and treat it as a plugin that can be used within the kernel. With native functions, you can doc complex calculations or call web services. Each method in the class can be designated as a function by decorating the method with the SKFunction attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// 2. Invoke the native function and provide the user's input\n",
    "FunctionResult result = await kernel.InvokeAsync(oePlugin[\"Translate\"], \n",
    "    new KernelArguments(){{\"input\", \"Death cannot stop true love. All it can do is delay it for a while.\"}});\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>()!);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. And similar to our previous examples, we just invoke the function and provide the user's prompt. This time we just provided the prompt string directly as a parameter to the invoke method, but it behaves exactly the same as previous examples.\n",
    "\n",
    "Hmmm...that may not have been the output we expected, but it is behaving correctly. Unlike the semantic and inline functions we saw above, native functions aren't intrinsically wired into OpenAI.\n",
    "\n",
    "If you want to incorporate AI into your function and need to work in code, consider inline functions first as they are simple, but if you want to add AI into your native function (or you really just want to see the Olde English interpretation of the quote above :) ), check out the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#!import Plugins/OldeEnglishPlugin2.cs\n",
    "\n",
    "// 1. load the other version of our plugin\n",
    "KernelPlugin oePlugin = kernel.ImportPluginFromObject(new OldeEnglishPlugin2());\n",
    "\n",
    "FunctionResult result = await kernel.InvokeAsync(oePlugin[\"Translate\"],\n",
    "    new KernelArguments(){{\"input\", \"Death cannot stop true love. All it can do is delay it for a while.\"}});\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>()!);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. That's a little better! Open the OldeEnglishPlugin2.cs file and compare it to the OldeEnglishPlugin.cs you looked at above. We'll look at different ways to use native functions in other tutorials."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "With each of the above functions now associated with the kernel, write code in the box below to invoke each function with your own input prompt and write the output of each to the Console window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Add your own semantic function to the Tutorial02 folder and test that you get the desired result.\n",
    "Add your own native function to the Tutorial02 folder and test that you get the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've achieved an important milestone because functions and skills/plugins are important building blocks of Semantic Kernel!\n",
    "\n",
    "You can probably imagine all kinds of things you could start creating! But check out the next tutorial because it's important we start putting all of these building blocks together."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
